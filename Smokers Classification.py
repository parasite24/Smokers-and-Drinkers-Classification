# -*- coding: utf-8 -*-
"""DM Project - Ronit, Paras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CbKqQlQXC8jAUkxhYOFgAEsDgmfzf9VB

# Dataset and Problem Description

This dataset is collected from National Health Insurance Service in Korea.


We're are going to do the following analysis on this dataset.

1. Classification of Drinker or not a Drinker and Smoker or not a Smoker.
  > This will be done by using the Body Signal attributes that the dataset offers such as Blood Pressure, Protein in urine etc.
2. Effect of Smoking or Drinking on the Body.
  > This can be done by comparing the Body Signals of a Smoker or a Drinker to the Body Signals of a person from the control group i.e. not a smoker or a drinker.

# Research Papers
1. https://www.diva-portal.org/smash/get/diva2:1537520/FULLTEXT01.pdf
 > A study in alcohol: A comparison of data mining methods for identifying binge drinking risk factors in university students


2. https://ieeexplore.ieee.org/document/8869001
 > A Comparative Study of Lung Cancer Detection using Machine Learning Algorithms.
"""

# To mount your Google Drive on your runtime using an authorization code
from google.colab import drive
drive.mount('/content/drive/')
import os
os.chdir('/content/drive/My Drive/Data Mining')

#imports
import pandas as pd
import numpy as np
import plotly.express as px

dataset = pd.read_csv('smokingdrinkingdataset.csv')
dataset.head()

"""# Data Preprocessing"""

dataset.info()

dataset.describe().T

dataset[dataset['sex'] == 'Male'].max()

dataset.isna().sum()

dataset.nunique()

"""For our Classification Problem, We'll find out whether a person is a drinker or not. This is given by the attribute **DRK_YN** where value 1 is for Yes person is a Drinker and 0 is for Not a Drinker.

There are 6 categorical and 18 numerical variables in our dataset.
We'll encode the categorial values with numerical values.
"""

numerical_cols = ['age', 'height', 'weight', 'waistline', 'sight_left', 'sight_right', 'SBP', 'DBP', 'BLDS', 'tot_chole', 'HDL_chole', 'LDL_chole', 'triglyceride', 'hemoglobin', 'serum_creatinine', 'SGOT_AST', 'SGOT_ALT', 'gamma_GTP']
categorical_cols = ['sex', 'DRK_YN', 'hear_left', 'hear_right', 'urine_protein', 'SMK_stat_type_cd']

dataset['DRK_YN'].replace({'Y':1, 'N':0}, inplace = True)
dataset['sex'].replace({"Male": 1, "Female": 0}, inplace = True)
dataset['SMK_stat_type_cd'].replace({1: 0, 2: 1, 3: 2}, inplace = True)

"""There are some duplicate values, but because the dataset have larger number of rows, we will simply drop the duplicate values."""

dataset.drop_duplicates(inplace = True)

"""Fixing Outliers"""

#Detecting which cols have outliers
def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):
  quartile1 = dataframe[col_name].quantile(q1)
  quartile3 = dataframe[col_name].quantile(q3)
  IQR = quartile3 - quartile1
  up_limit = quartile3 + (1.5*IQR)
  low_limit = quartile1 - (1.5*IQR)
  return low_limit, up_limit

def check_outlier(dataset, col_name):
  low_limit, up_limit = outlier_thresholds(dataset, col_name)
  if dataset[(dataset[col_name] > up_limit) | (dataset[col_name] < low_limit)].any(axis=None):
    return True
  else:
    return False

outlier_cols = []
for col in numerical_cols:
  if check_outlier(dataset, col):
    outlier_cols.append(col)
    print(col)

#fix outliers by winsorizing
def winsorize(dataframe, col_name, lower_quantile, upper_quantile):
  lower_limit, upper_limit = outlier_thresholds(dataframe, col_name, q1=lower_quantile, q3=upper_quantile)
  dataframe[col_name] = dataframe[col_name].apply(lambda x: lower_limit if x < lower_limit else (upper_limit if x > upper_limit else x))

for col in outlier_cols:
  winsorize(dataset, col, 0.05, 0.95)

"""Since we have Height and Weight in our data, we can create a BMI column and a BMI_Category column."""

dataset['BMI'] = dataset['weight'] / ((dataset['height'] / 100) ** 2)
conditions = [
    (dataset['BMI'] < 18.5),  #Underweight
    (dataset['BMI'] >= 18.5) & (dataset['BMI'] < 25),  #Normal
    (dataset['BMI'] >= 25) & (dataset['BMI'] < 30),  #Overweight
    (dataset['BMI'] >= 30)]  #Obese

dataset['BMI_Category'] = pd.cut(dataset['BMI'], bins=[0, 18.5, 25, 30, float('inf')], labels=[0, 1, 2, 3])

"""# EDA"""

dataset.head()

fig = px.histogram(dataset, x="age", color="DRK_YN")
fig.show()

dataset['age'].describe()

fig = px.histogram(dataset, x="weight", color="DRK_YN")
fig.show()

dataset['weight'].describe()

import pandas as pd
import numpy as np
corr = dataset.corr()
corr.style.background_gradient(cmap='coolwarm')

"""# Modelling

Feature encoding and transformation
"""

from sklearn.preprocessing import MinMaxScaler

#Processing Million Samples is v slow therefore we'll worth with a subset of the dataset
dataset = dataset.sample(n=100000)

columns_to_scale = dataset.columns.difference(["DRK_YN", "SMK_stat_type_cd",'sex']) #as we already encoded these above

scaler = MinMaxScaler()

scaled_data = scaler.fit_transform(dataset[columns_to_scale])
scaled_df = pd.DataFrame(scaled_data, columns=columns_to_scale)

scaled_dataset = dataset.copy()
scaled_dataset = scaled_dataset.reset_index(drop=True)
scaled_dataset[columns_to_scale] = scaled_df
scaled_dataset.head()

"""Model for Drinker or Not (2 Class)"""

from sklearn.model_selection import train_test_split
X = scaled_dataset.drop(["DRK_YN", "SMK_stat_type_cd"], axis=1)
Y = scaled_dataset["DRK_YN"]
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report,confusion_matrix, roc_curve,auc,ConfusionMatrixDisplay
import seaborn as sns
import matplotlib.pyplot as plt

def models_drinking(models, X_train, X_test, Y_train, Y_test):
  results = {}

  for model_name, model_conf in models.items():
    model = models[model_name]
    model.fit(X_train, Y_train)
    Y_pred = model.predict(X_test)

    print("-----------",model_name,"-----------\n")

    #Roc curve
    fpr, tpr, _ = roc_curve(Y_test, Y_pred)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, lw=2, label=f'{model_name} Model (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'{model_name} ROC Curve : ')
    plt.legend(loc='lower right')
    plt.show()

    #Classifcation report
    report = classification_report(Y_test, Y_pred, target_names=["Yes","No"], output_dict=True)
    report_df = pd.DataFrame(report).transpose()
    print(report_df)

    #Confusion matrix
    conf_matrix = confusion_matrix(Y_test, Y_pred)
    cm_display = ConfusionMatrixDisplay(conf_matrix, display_labels = [False, True])
    cm_display.plot()
    plt.figure(figsize=(8, 6))
    plt.show()

classification_models = {
    'DecisionTreeClassifier': DecisionTreeClassifier(),
    'LogisticRegression': LogisticRegression(max_iter=50, n_jobs=-1),
    'RandomForestClassifier': RandomForestClassifier(n_jobs=-1),
}

models_drinking(classification_models, X_train, X_test, Y_train, Y_test)

"""Model for Smoker type (3 Class)"""

from sklearn.model_selection import train_test_split
X = scaled_dataset.drop(["DRK_YN", "SMK_stat_type_cd"], axis=1)
Y = scaled_dataset["SMK_stat_type_cd"]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)

from sklearn.metrics import roc_auc_score,accuracy_score,precision_score,recall_score,roc_curve,auc,f1_score,ConfusionMatrixDisplay
def models_smoker(models, X_train, X_test, Y_train, Y_test):
  results = {}

  for model_name, model_conf in models.items():
    model = models[model_name]
    model.fit(X_train, Y_train)
    Y_pred = model.predict(X_test)
    Y_prob = model.predict_proba(X_test)

    print("-----------",model_name,"-----------\n")

    #Roc curve
    fpr = {}
    tpr = {}
    roc_auc = {}

    for i in range(3):
      fpr[i], tpr[i], _ = roc_curve(Y_test, Y_prob[:, i], pos_label=i)
      roc_auc[i] = auc(fpr[i], tpr[i])

    # Plot ROC curves for each class
    plt.figure(figsize=(8, 6))
    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']
    for i, color in zip(range(3), colors):
        plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')

    plt.plot([0, 1], [0, 1], lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'{model_name} ROC Curve : ')
    plt.legend(loc="lower right")
    plt.show()

    #Metrics
    auc_roc = roc_auc_score(Y_test, Y_prob, multi_class='ovr')
    accuracy = accuracy_score(Y_test, Y_pred)
    precision = precision_score(Y_test, Y_pred, average='weighted', zero_division=1)  # Specify 'weighted' averaging
    recall = recall_score(Y_test, Y_pred, average='weighted')  # Specify 'weighted' averaging
    f1 = f1_score(Y_test, Y_pred, average='weighted')
    results[model_name] = {
            'ROC AUC': auc_roc,
            'Accuracy': accuracy,
            'Precision': precision,
            'Recall': recall,
            'F1 Score': f1,
        }

    print(f"Model: {model_name}")
    print(f"ROC AUC: {auc_roc}")
    print(f"Accuracy: {accuracy}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")
    print(f"F1 Score: {f1}\n")


classification_models = {
    'DecisionTreeClassifier': DecisionTreeClassifier(),
    'LogisticRegression': LogisticRegression(max_iter=50,n_jobs=-1),
    'RandomForestClassifier': RandomForestClassifier(n_jobs=-1),
}

models_smoker(classification_models, X_train, X_test, Y_train, Y_test)